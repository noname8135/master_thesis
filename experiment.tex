\chapter{Detection Method Implementation and Evaluation}
In this chapter, we evaluate the methods presented in Chapter 3. First, the environment and the reason of using them will be explained. Then, we will show test items and their corresponding results.

\section{General setup}
Table~~\ref{table:Experiment_table} is a summary of all the tools and their versions in the evaluation. We use Mininet to simulate the data center network \cite{Mininet}. It allows us to creates a large-scale virtual network easily. It provides python API as well as command line interface to customize the network. It also offers an interactive interface to test the connectivity and performance.

\begin{table}[H]
\centering
\caption{Experimental environment summary}
\begin{tabular}{|l|p{4cm}|p{4.5cm}}
\hline Item & Detail version \\
\hline Operating system & Ubuntu 14.04 x86\_64 \\
\hline Controller & Ryu\_manager 4.0 \\
\hline Network Emulator & Mininet 2.2.1 \\
\hline Topology generator & Fast Network Simulation Setup (FNSS) 0.6.1\\
\hline Packet Generator & Ryu packet library API \\
\hline Southbound API & OpenFlow 1.3 \\
\hline Virtual switch & OpenvSwitch 2.5.0 \\
\hline 
\end{tabular}
\label{table:Experiment_table}
\end{table}

To evaluate the effectiveness of the detection method under different environment, there will be XXXX different network topologies in our experiment, they are generated by Fast Network Simulation Setup, known as FNSS, which is a python module that is able to generate plenty types of network topology for experiment. It not only supports datacenter network topologies, which is suitable for our background assumption, but also provides Mininet API, making it extremely easy to import the generated topology into Mininet. The network topologies we use are two-tier topology, three-tier topology and fat tree topology, there will be multiple sizes of each of them. The detail including number of switch and average number of link between two switches of topologies is shown as Table~~\ref{table:network_env}. The numbers in the topology name are parameters such as number of core switches, aggregation switches or edge switches, which effect network size. These parameters have the same meaning as the ones in \cite{FNSS}.

\begin{table}[H]
\centering
\caption{Detailed of network topologies}
\begin{tabular}{|l|l|l|l|}
\hline  topology type & number of switch & average number of link\\
\hline fat\_tree\_2 & 5 & 2 \\
\hline fat\_tree\_4 & 20 & 4 \\
\hline fat\_tree\_6 & 45 & 6 \\
\hline fat\_tree\_8 & 80 & 8 \\
\hline fat\_tree\_10 & 125 & 10 \\
\hline two\_tier\_2\_3 & 5 & 3 \\
\hline two\_tier\_3\_4 & 7 & 4 \\
\hline two\_tier\_4\_4 & 8 & 4.5 \\
\hline two\_tier\_5\_4 & 9 & 4.8 \\
\hline two\_tier\_6\_8 & 14 & 7.42 \\
\hline two\_tier\_8\_10 & 18 & 9.4 \\
\hline two\_tier\_12\_8 & 20 & 10 \\
\hline two\_tier\_12\_12 & 24 & 12.5 \\
\hline two\_tier\_16\_18 & 34 & 17.47 \\
\hline three\_tier\_2\_3\_3 & 14 & 2.79 \\
\hline three\_tier\_3\_4\_5 & 27 & 3.11 \\
\hline three\_tier\_4\_4\_4 & 24 & 3.33 \\
\hline three\_tier\_4\_3\_2 & 13 & 3.23 \\
\hline three\_tier\_6\_6\_6 & 48 & 3.75 \\
\hline 
\end{tabular}
\label{table:network_env}
\end{table}

The in-band control is used for control channel. It is the default setting of Mininet and is more convenient to set up. Although there will be special flow entries in-band control channel, they are hidden and will not have any influence on our experiment. Hosts are irrelevant in our method, so there will be only minimal number of hosts in our network environment in order to make the topology reasonable, and one controller is used. 

There are 254 flow tables in OpenFlow switch simulated by Mininet. In order to simulate the flow entries exist in the OpenFlow switches in the network, the flow entry are installed pro-actively, and due to the reason stated in the last paragraph of Section~\ref{Further_discussion}, the controller will maintain a record of switches, including ports, links and flow entries. 

The core algorithm of flow entry detection method is implemented as a Ryu controller application. It obtains essential information from the configure files, find aggregated groups, generate raw packets and send them by Packet\_Out, and check Packet\_in to see if the packets come back as expected. Packets are generated by Ryu's built-in API library. In order to send PACKET\_OUT with raw packet, the action should be set ``forwarding to OFPP\_TABLE'', which means after the action is executed, the packet is sent to the first flow table, otherwise Packet\_Out will not be processed as normal traffic packet, the action set will be executed directly without going through the processing pipeline \cite{PACKETOUT}. Due to the reason stated in the last paragraph of \ref{Further_discussion}, the detection packets from the controller should be sent to a normal port rather than the default controller-specifying port OFPP\_CONTROLLER. 

\section{Flow entry generation}
We choose the fields that are more common and avoid the dependency field such as ether type, IP protocol type. The chosen fields in the field set are the fields that will be in our experimental network environment. Just like what is mentioned in the third paragraph of Section~\ref{SDN and OpenFlow}, although we intend to keep the match fields simple and have only one match field and one match value for each flow entry, the flow entries should still have additional dependent match fields. The chosen set is listed as follow:

\begin{itemize}
\item
ethernet layer: eth\_dst, eth\_src
\item
ip layer: ipv4\_src, ipv4\_dst
\item
tcp/udp/icmp layer: tcp\_src, tcp\_dst, udp\_src, udp\_dst, icmpv4\_type, icmpv4\_code
\end{itemize}

The topology generating file randomly generates flow entries, and Ryu application installs them on switches. When a flow entry is generated, the script selects a random match field from the set of chosen match fields along with random value in valid range and format, and select the output port and the switch this entry is on randomly. Due to the reason stated in Section~\ref{Further_discussion}, there will be only ``output port\_no'' action in all the flow entries. In order to make the scenario more realistic, the following setup is considered while flow entry generation:

\begin{itemize}
\item 
The cookie field is used as an identifier for every entry, it is a unique integer from 0 to total entry number minus one. 
\item
Since the two entries with same priority which is possible to match a same packet might cause undefined behavior \cite{OF_SPEC}, the priority of entries on the same switch are different.
\item
There will be duplicate field and value set deliberately generated with 20\% chance. It is quite reasonable to have duplicate on different switches. 
\item
The IP is restricted to a class C.
\item
It is hard to find a fair way to decide the number of flow entry on each switch, since it depends on the way of routing\cite{MPFHMRSV09}. In order to keep it simple, the number of entry on every switches are the same. 
\item
According to a firewall log found on the Internet \cite{PORT_FREQ}, the occurrences frequency of TCP ports are distributed in follow percentage in order to make it closer to real case:
\begin{itemize}
\item
port 80: 50\%
\item
port 443: 25\%
\item
other common ports (7,20,21,22,23,25,43,53,109,110,156,161,194,546,547): 15\%
\item
other ports in 1024: 10\%
\end{itemize}
\end{itemize}

\section{Experiment test item and result}

\subsection{Influence of topology type}

\subsection{Influence of network scale}
XXXXX put different type of topology with roughly the same amount of switch here XXXXX
\subsection{Influence of flow entry number}


\section{Evaluation}

\subsection{Estimated expectation}
XXXXXXXXXX put big O analysis here XXXXXXXXXXXXXXX
